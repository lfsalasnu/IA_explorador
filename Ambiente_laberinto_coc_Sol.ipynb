{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "833a42c92da63dad82a57185a7101303",
          "grade": false,
          "grade_id": "cell-7def3dbbdb35eb5a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0769e1b8"
      },
      "source": [
        "## Ambiente 游깵\n",
        "\n",
        "El ambiente de Gridworld se define como una cuadricula de `nxm`. El ambiente tiene obst치culos, es decir casillas por las cuales no puede pasar el agente. Al chocar con un obst치culo, el agente termina en la misma casilla en la que estaba. Un comportamiento similar se observa cuando el agente trata de salir de los bordes del ambiente. Adem치s, el ambiente tiene una casilla de inicio definida, y algunas casillas de salida (determinadas por la recompensa asociada a ellas). Un ejemplo del ambiente para el caso `3x4` se muestra a continuaci칩n.\n",
        "\n",
        "![gridworld.png](https://raw.githubusercontent.com/lfsalasnu/IA_explorador/refs/heads/main/gridworld.png)\n",
        "\n",
        "En este ejemplo del ambiente la casilla de inicio es la casilla inferior izquierda y tiene como objetivo llegar a la casilla de salida con recompensa 1. La otra casilla de salida tiene recompensa -1.\n",
        "\n",
        "\n",
        "#### 쮺칩mo podemos codificar el ambiente?\n",
        "\n",
        "La definici칩n del ambiente de Gridworld esta definida por:\n",
        "1. Una cuadr칤cula rectangular (`grid`), con dimensiones `(n,m)` dadas por par치metro, donde la casilla superior izquierda esta en la posici칩n (0,0). Definiremos las casillas por las que puede pasar el agente como espacios en blanco y las casillas por las que no puede pasar el agente con un `'#'`.\n",
        "2. Las recompensas de cada casilla de la cuadr칤cula estan definidas dentro de la definici칩n de `grid`.\n",
        "    - +1 para la casilla objetivo\n",
        "    - -1 para las casillas de trampa\n",
        "3. Un atributo con el estado actual (`state`) en el que se encuentra el agente. Por defecto este estado ser치 la posici칩n marcada como `S`.\n",
        "\n",
        "Un ejemplo de una cuadr칤cula de 3x4, como se mostr칩 anteriormente, ser칤a as칤:\n",
        "\n",
        " ```python  \n",
        "    board = [[' ', ' ', ' ',  +1],\n",
        "            [' ', '#', ' ',  -1],\n",
        "             ['S', ' ', ' ', ' ']]\n",
        "```\n",
        "\n",
        "La definici칩n del ambiente un ejemplo de recompensas se ver칤a as칤:\n",
        "\n",
        "```python\n",
        "    def __init__(self, board):\n",
        "        # layout\n",
        "        self.grid = copy_elements_from_the_board\n",
        "```\n",
        "\n",
        "\n",
        "#### 1. Estructura del ambiente\n",
        "\n",
        "Defina la clase `Gridworld`, que recibe una cuadr칤cula con la descripci칩n del tablero `board`, definidos como en el ejemplo. La informaci칩n codificada en la cuadr칤cula ser치 almacenada en el atributo `grid` del ambiente (este atributo corresponde al mdp donde se almacena la informaci칩n del ambiente, la funci칩n de transici칩n y las recompensas). Adicionalmente, para facilitar el uso del mdp, definimos los atributos para guardar la informaci칩n de la cuadr칤cula; las filas (`nrows`) y columnas (`ncols`). esta informaci칩n se da por par치metro (`dimensions`), al instanciar la clase, como una tupla con los valores respectivos. Adicionalmente la clase debe tener los atributos `initial_state` y `state` que corresponden al estado inicial y el estado actual del agente en el ambiente, respectivamente. Estos atributos se guardan como tuplas.\n",
        "\n",
        "Finalmente, el atributo `grid` se debe codificar de tal forma que las casillas prohibidas (marcadas como `'#'`) no deben tener ning칰n valor asignado (su valor debe ser `None`), las casillas en blanco deben tener valor `0`, y las casillas con recompensas asociadas deben tener el valor de la recompensa como su valor. Note que con esta codificaci칩n de `grid`, y teniendo en cuenta que las acciones son determin칤sticas, estamos codificando directamente las recompensas del ambiente. Si este no fuera el caso, ser칤a necesario definir un nuevo atributo `rewards`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3dbebfa0c0d4d46d7fb5d6df9107eef",
          "grade": false,
          "grade_id": "cell-11f1d5794939d3dd",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2c83e984"
      },
      "outputs": [],
      "source": [
        "#Definici칩n del ambiente de gridworld\n",
        "\n",
        "#Librerias de gr치ficas\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "#Definici칩n de la clase principal\n",
        "class Gridworld:\n",
        "    def __init__(self, board, dimensions):\n",
        "        # your code here\n",
        "        self.nrows = dimensions[0]\n",
        "        self.ncols = dimensions[1]\n",
        "        tablero=[]\n",
        "        for i in range(self.nrows):\n",
        "          fila=[]\n",
        "          for j in range(self.ncols):\n",
        "            if board[i][j]==' ':\n",
        "              fila.append(0)\n",
        "            elif board[i][j]=='#':\n",
        "              fila.append(None)\n",
        "            elif board[i][j]=='+1':\n",
        "              fila.append(1)\n",
        "            elif board[i][j]=='S':\n",
        "              self.initial_state = (i,j)\n",
        "              fila.append(0)\n",
        "            else:\n",
        "              fila.append(-1)\n",
        "          tablero.append(fila)\n",
        "        self.grid = tablero.copy()\n",
        "        self.state = self.initial_state\n",
        "\n",
        "    def get_current_state(self):\n",
        "        # your code here\n",
        "        #raise NotImplementedError\n",
        "        return self.state\n",
        "\n",
        "    def get_possible_actions(self, state):\n",
        "        # your code here\n",
        "        if self.grid[state[0]][state[1]] == 0:\n",
        "          return ['up', 'right', 'down', 'left']\n",
        "        elif self.grid[state[0]][state[1]] == None:\n",
        "          return []\n",
        "        elif self.grid[state[0]][state[1]] == 1 or self.grid[state[0]][state[1]] == -1:\n",
        "          return ['exit']\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    def do_action(self, action):\n",
        "        # your code here\n",
        "        # el estado esta en el atributo self.state\n",
        "        x,y=self.state\n",
        "        if action == 'left' and y > 0 and self.grid[x][y-1]!=None:\n",
        "          y=y-1\n",
        "        elif action == 'down' and x < self.ncols-1:\n",
        "          if self.grid[x+1][y]!=None:\n",
        "            x=x+1\n",
        "        elif action == 'right' and y < self.nrows and self.grid[x][y+1]!=None:\n",
        "          y=y+1\n",
        "        elif action == 'up' and x > 0 and self.grid[x-1][y]:\n",
        "          x=x-1\n",
        "        self.state = (x,y)\n",
        "        return self.grid[x][y], self.state\n",
        "\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.initial_state\n",
        "        # your code here\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # your code here\n",
        "        if self.grid[self.state[0]][self.state[1]] == 1 or self.grid[self.state[0]][self.state[1]] == -1:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "        #raise NotImplementedError\n",
        "\n",
        "    #Funciones auxiliares\n",
        "    def get_action_index(self, action):\n",
        "        actions = ['up', 'right', 'down', 'left']\n",
        "        index = 0\n",
        "        for a in actions:\n",
        "            if action == a:\n",
        "                return index\n",
        "            index += 1\n",
        "\n",
        "    def plot(self):\n",
        "        fig1 = plt.figure(figsize=(3, 3))\n",
        "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
        "\n",
        "        # Lineas\n",
        "        for i in range(0, len(self.grid)+1):\n",
        "            ax1.axhline(i , linewidth=2, color=\"#2D2D33\")\n",
        "            ax1.axvline(i , linewidth=2, color=\"#2D2D33\")\n",
        "\n",
        "        # Amarillo - estado inicial\n",
        "        (i,j)  = self.initial_state\n",
        "        ax1.add_patch(patches.Rectangle((j, self.nrows - i -1), 1, 1, facecolor = \"#F6D924\"))\n",
        "        for j in range(len(self.grid[0])):\n",
        "            for i in range(len(self.grid)):\n",
        "                if self.grid[i][j] == 1: # verde\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#68FF33\"))\n",
        "                if self.grid[i][j] == None: # gris\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#6c7780\"))\n",
        "                if self.grid[i][j] == -1: # rojo\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#cc0000\"))\n",
        "        plt.scatter(self.state[1] + 0.5, self.nrows - self.state[0] - 1 +0.5, s = 100, color = \"black\", marker = \"o\", facecolor = \"blue\", edgecolors = \"blue\", zorder = 10)\n",
        "        for i in range(len(self.grid)):\n",
        "            for j in range(len(self.grid[0])):\n",
        "                if self.grid[i][j] == None:\n",
        "                    ax1.text(self.ncols-j-1, self.nrows-i-1, \"\", ha='center', va='center')\n",
        "                else:\n",
        "                    ax1.text(j+0.5, self.nrows-i-1+0.5, self.grid[i][j], ha='center', va='center')\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5b66ef3329c55eec92d22fd33bb252df",
          "grade": true,
          "grade_id": "cell-d02ebef01da3ead9",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e1ca18e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "a31391c9-057c-480c-e273-a4eed87a7ff8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Pruebas estructura del ambiente\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "#board = [[' ', ' ', ' ', ' ', '-1'],\n",
        "#      ['S', '#', ' ', ' ', ' '],\n",
        "#      [' ', '#', ' ', ' ', ' '],\n",
        "#      [' ', '#', ' ', ' ', ' '],\n",
        "#      [' ', ' ', '+1',' ', ' ']]\n",
        "# grid\n",
        "grid = [[0, 0    ,-1],\n",
        "        ['S',None, 0],\n",
        "        [ 0,   0,  1]]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.nrows\n",
        "except:\n",
        "    print(\"El atributo nrows no est치 definido\")\n",
        "try:\n",
        "    grid.ncols\n",
        "except:\n",
        "    print(\"El atributo ncols no est치 definido\")\n",
        "try:\n",
        "    grid.initial_state\n",
        "except:\n",
        "    print(\"El atributo initial_state no est치 definido\")\n",
        "\n",
        "try:\n",
        "    grid.state\n",
        "except:\n",
        "    print(\"El atributo state no est치 definido\")\n",
        "\n",
        "try:\n",
        "    grid.grid\n",
        "except:\n",
        "    print(\"El atributo grid no est치 definido\")\n",
        "\n",
        "### END TESTS\n",
        "\n",
        "grid.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f9966fc40d95a55467d6d8035edfc543",
          "grade": false,
          "grade_id": "cell-449b5d30df6612e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8cdc76dc"
      },
      "source": [
        "#### 2. Movimientos del agente\n",
        "\n",
        "Defina la funci칩n `do_action` que ejecuta la acci칩n tomada por el agente dentro de la cuadr칤cula. Esta funci칩n recibe como par치metro la acci칩n a ejecutar y retorna el valor de la casilla de llegada de la acci칩n y el estado de llegada de la acci칩n (como una tupla). Note que los movimientos fuera del tablero o las casillas prohibidas no deber칤an tener ning칰n efecto en la posici칩n del agente (el agente se debe mantener en la misma posici칩n de partida).\n",
        "\n",
        "En esta versi칩n de gridworld vamos a trabajar con acciones determin칤sticas, es decir el movimiento deseado del agente (`up`,`right`,`down`,`left`) siempre resultara en el estado esperado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1eb73f2b6fe47f3dd5e95d11c93f5863",
          "grade": false,
          "grade_id": "cell-cef0ee02db9824ce",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fbf0a92c"
      },
      "source": [
        "#### 3. Estado actual\n",
        "\n",
        "Defina la funci칩n `get_current_state` que retorna el estado actual del agente (la casilla donde se encuentra el agente). Esta funci칩n no recibe ning칰n par치metro y retorna el estado actual como una tupla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a87b8280f7eaf836d1684523f69c4048",
          "grade": false,
          "grade_id": "cell-a2363364694eb96e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "817babdf"
      },
      "source": [
        "#### 4. Obtener las acciones\n",
        "\n",
        "Defina la funci칩n `get_possible_actions` que recibe el estado actual del agente por par치metro y retorna una lista de las acciones v치lidas para el estado dado.\n",
        "\n",
        "Tenga en cuenta que en esta versi칩n de Gridworld, todas las acciones (i.e., los movimientos en las cuatro direcciones) son posibles para el agente en cada una de las casillas regulares de la cuadr칤cula. Las casillas de salida tienen 칰nica acci칩n posible `'exit'` y las casillas prohibidas no tienen ning칰na acci칩n asociada (una lista vac칤a de acciones)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a939f732e5e93ebcde4c50f067062c07",
          "grade": false,
          "grade_id": "cell-d76f87aa491607d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ffa06d65"
      },
      "source": [
        "\n",
        "#### 5. Reinicializar el ambiente\n",
        "\n",
        "Defina la funci칩n `reset` que no recibe par치metros ni retorna ning칰n valor. El efecto de esta funci칩n es restablecer el ambiente a su estado inicial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0a85ca59c65b35130dd2eb2a1e8dff78",
          "grade": false,
          "grade_id": "cell-5761e4534eaa648f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0a9d4f38"
      },
      "source": [
        "\n",
        "#### 6. Estados terminales\n",
        "\n",
        "Defina la funci칩n `is_terminal` que determina si el agente est치 en un estado final o no. En nuestro caso los estados finales o los estados de salida estar치n determinados por las casillas con recompensa 1 o -1.\n",
        "Esta funci칩n no recibe par치metros y retorna un booleano determinando si el agente est치 en un estado final o no."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agente Reflexivo\n",
        "\n",
        "- Defina por medio de un `while` un agente reflexivo.\n",
        "- Cuente la cantidad de pasos para llegar al estado terminal.\n",
        "- Ejecute 50 episodios del ambiente con el agente reflexivo, calcule la cantidad de veces que se gana el juego del laberinto y calcule el promedio de pasos para ganar.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Um2crzX7jMbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "laberinto = Gridworld(board, (3,3))\n",
        "# Defina por medio de un while un agente reflexivo.\n",
        "hist = []\n",
        "for i in range(50):\n",
        "  laberinto.reset()\n",
        "  # Cuente la cantidad de pasos para llegar al estado terminal.\n",
        "  pasos = 0\n",
        "  while True:\n",
        "      #laberinto.plot()\n",
        "      x,y=laberinto.get_current_state()\n",
        "      #print(x,y)\n",
        "      if x!=laberinto.nrows-1:\n",
        "        if laberinto.grid[x+1][y]==1:\n",
        "          laberinto.do_action('down')\n",
        "          pasos+=1\n",
        "      if x!=0:\n",
        "        if laberinto.grid[x-1][y]==1:\n",
        "          laberinto.do_action('up')\n",
        "          pasos+=1\n",
        "      if y!=laberinto.ncols-1:\n",
        "        if laberinto.grid[x][y+1]==1:\n",
        "          laberinto.do_action('right')\n",
        "          pasos+=1\n",
        "      if y!=0:\n",
        "        if laberinto.grid[x][y-1]==1:\n",
        "          laberinto.do_action('left')\n",
        "          pasos+=1\n",
        "      else:\n",
        "        opc = random.choice(['up', 'right', 'down', 'left'])\n",
        "        laberinto.do_action(opc)\n",
        "        pasos+=1\n",
        "      if laberinto.is_terminal():\n",
        "        #laberinto.plot()\n",
        "        break\n",
        "      #if laberinto.grid[x][y] == 1 or laberinto.grid[x][y] == -1:\n",
        "      #  break\n",
        "      #laberinto.do_action('up')\n",
        "  hist.append(pasos)\n",
        "print(hist)\n",
        "print(sum(hist)/len(hist))\n",
        "  #print('La cantidad de pasos es:',pasos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiXdLdpjkCjM",
        "outputId": "4fa6d2b9-a7b9-47b4-cdbd-3cc6357a5fd0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12, 16, 11, 13, 16, 5, 6, 4, 4, 6, 5, 4, 5, 9, 6, 10, 8, 12, 11, 9, 10, 7, 9, 9, 10, 5, 5, 5, 11, 14, 15, 13, 14, 10, 6, 11, 13, 13, 4, 3, 19, 13, 8, 15, 20, 19, 3, 14, 14, 18]\n",
            "10.04\n"
          ]
        }
      ]
    }
  ]
}