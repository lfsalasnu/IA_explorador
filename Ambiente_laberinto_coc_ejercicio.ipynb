{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "833a42c92da63dad82a57185a7101303",
          "grade": false,
          "grade_id": "cell-7def3dbbdb35eb5a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0769e1b8"
      },
      "source": [
        "## Ambiente 🌎\n",
        "\n",
        "El ambiente de Gridworld se define como una cuadricula de `nxm`. El ambiente tiene obstáculos, es decir casillas por las cuales no puede pasar el agente. Al chocar con un obstáculo, el agente termina en la misma casilla en la que estaba. Un comportamiento similar se observa cuando el agente trata de salir de los bordes del ambiente. Además, el ambiente tiene una casilla de inicio definida, y algunas casillas de salida (determinadas por la recompensa asociada a ellas). Un ejemplo del ambiente para el caso `3x4` se muestra a continuación.\n",
        "\n",
        "![gridworld.png](https://raw.githubusercontent.com/lfsalasnu/IA_explorador/refs/heads/main/gridworld.png)\n",
        "\n",
        "En este ejemplo del ambiente la casilla de inicio es la casilla inferior izquierda y tiene como objetivo llegar a la casilla de salida con recompensa 1. La otra casilla de salida tiene recompensa -1.\n",
        "\n",
        "\n",
        "#### ¿Cómo podemos codificar el ambiente?\n",
        "\n",
        "La definición del ambiente de Gridworld esta definida por:\n",
        "1. Una cuadrícula rectangular (`grid`), con dimensiones `(n,m)` dadas por parámetro, donde la casilla superior izquierda esta en la posición (0,0). Definiremos las casillas por las que puede pasar el agente como espacios en blanco y las casillas por las que no puede pasar el agente con un `'#'`.\n",
        "2. Las recompensas de cada casilla de la cuadrícula estan definidas dentro de la definición de `grid`.\n",
        "    - +1 para la casilla objetivo\n",
        "    - -1 para las casillas de trampa\n",
        "3. Un atributo con el estado actual (`state`) en el que se encuentra el agente. Por defecto este estado será la posición marcada como `S`.\n",
        "\n",
        "Un ejemplo de una cuadrícula de 3x4, como se mostró anteriormente, sería así:\n",
        "\n",
        " ```python  \n",
        "    board = [[' ', ' ', ' ',  +1],\n",
        "            [' ', '#', ' ',  -1],\n",
        "             ['S', ' ', ' ', ' ']]\n",
        "```\n",
        "\n",
        "La definición del ambiente un ejemplo de recompensas se vería así:\n",
        "\n",
        "```python\n",
        "    def __init__(self, board):\n",
        "        # layout\n",
        "        self.grid = copy_elements_from_the_board\n",
        "```\n",
        "\n",
        "\n",
        "#### 1. Estructura del ambiente\n",
        "\n",
        "Defina la clase `Gridworld`, que recibe una cuadrícula con la descripción del tablero `board`, definidos como en el ejemplo. La información codificada en la cuadrícula será almacenada en el atributo `grid` del ambiente (este atributo corresponde al mdp donde se almacena la información del ambiente, la función de transición y las recompensas). Adicionalmente, para facilitar el uso del mdp, definimos los atributos para guardar la información de la cuadrícula; las filas (`nrows`) y columnas (`ncols`). esta información se da por parámetro (`dimensions`), al instanciar la clase, como una tupla con los valores respectivos. Adicionalmente la clase debe tener los atributos `initial_state` y `state` que corresponden al estado inicial y el estado actual del agente en el ambiente, respectivamente. Estos atributos se guardan como tuplas.\n",
        "\n",
        "Finalmente, el atributo `grid` se debe codificar de tal forma que las casillas prohibidas (marcadas como `'#'`) no deben tener ningún valor asignado (su valor debe ser `None`), las casillas en blanco deben tener valor `0`, y las casillas con recompensas asociadas deben tener el valor de la recompensa como su valor. Note que con esta codificación de `grid`, y teniendo en cuenta que las acciones son determinísticas, estamos codificando directamente las recompensas del ambiente. Si este no fuera el caso, sería necesario definir un nuevo atributo `rewards`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3dbebfa0c0d4d46d7fb5d6df9107eef",
          "grade": false,
          "grade_id": "cell-11f1d5794939d3dd",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2c83e984"
      },
      "outputs": [],
      "source": [
        "#Definición del ambiente de gridworld\n",
        "\n",
        "#Librerias de gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "#Definición de la clase principal\n",
        "class Gridworld:\n",
        "    def __init__(self, board, dimensions):\n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_current_state(self):\n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_possible_actions(self, state):\n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def do_action(self, action):\n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def reset(self):\n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    #Funciones auxiliares\n",
        "    def get_action_index(self, action):\n",
        "        actions = ['up', 'right', 'down', 'left']\n",
        "        index = 0\n",
        "        for a in actions:\n",
        "            if action == a:\n",
        "                return index\n",
        "            index += 1\n",
        "\n",
        "    def plot(self):\n",
        "        fig1 = plt.figure(figsize=(10, 10))\n",
        "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
        "\n",
        "        # Lineas\n",
        "        for i in range(0, len(self.grid)+1):\n",
        "            ax1.axhline(i , linewidth=2, color=\"#2D2D33\")\n",
        "            ax1.axvline(i , linewidth=2, color=\"#2D2D33\")\n",
        "\n",
        "        # Amarillo - estado inicial\n",
        "        (i,j)  = self.initial_state\n",
        "        ax1.add_patch(patches.Rectangle((j, self.nrows - i -1), 1, 1, facecolor = \"#F6D924\"))\n",
        "        for j in range(len(self.grid[0])):\n",
        "            for i in range(len(self.grid)):\n",
        "                if self.grid[i][j] == 1: # verde\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#68FF33\"))\n",
        "                if self.grid[i][j] == None: # gris\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#6c7780\"))\n",
        "                if self.grid[i][j] == -1: # rojo\n",
        "                    ax1.add_patch(patches.Rectangle((j,self.nrows - i -1), 1, 1, facecolor = \"#cc0000\"))\n",
        "        plt.scatter(self.state[1] + 0.5, self.nrows - self.state[0] - 1 +0.5, s = 100, color = \"black\", marker = \"o\", facecolor = \"blue\", edgecolors = \"blue\", zorder = 10)\n",
        "        for i in range(len(self.grid)):\n",
        "            for j in range(len(self.grid[0])):\n",
        "                if self.grid[i][j] == None:\n",
        "                    ax1.text(self.ncols-j-1, self.nrows-i-1, \"\", ha='center', va='center')\n",
        "                else:\n",
        "                    ax1.text(j+0.5, self.nrows-i-1+0.5, self.grid[i][j], ha='center', va='center')\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5b66ef3329c55eec92d22fd33bb252df",
          "grade": true,
          "grade_id": "cell-d02ebef01da3ead9",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e1ca18e5"
      },
      "outputs": [],
      "source": [
        "#Pruebas estructura del ambiente\n",
        "### BEGIN TESTS\n",
        "board = [[' ', ' ', '-1'],\n",
        "      ['S', '#', ' '],\n",
        "      [' ', ' ', '+1']]\n",
        "\n",
        "grid = Gridworld(board, (3,3))\n",
        "\n",
        "try:\n",
        "    grid.nrows\n",
        "except:\n",
        "    print(\"El atributo nrows no está definido\")\n",
        "try:\n",
        "    grid.ncols\n",
        "except:\n",
        "    print(\"El atributo ncols no está definido\")\n",
        "try:\n",
        "    grid.initial_state\n",
        "except:\n",
        "    print(\"El atributo initial_state no está definido\")\n",
        "\n",
        "try:\n",
        "    grid.state\n",
        "except:\n",
        "    print(\"El atributo state no está definido\")\n",
        "\n",
        "try:\n",
        "    grid.grid\n",
        "except:\n",
        "    print(\"El atributo grid no está definido\")\n",
        "\n",
        "### END TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f9966fc40d95a55467d6d8035edfc543",
          "grade": false,
          "grade_id": "cell-449b5d30df6612e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8cdc76dc"
      },
      "source": [
        "#### 2. Movimientos del agente\n",
        "\n",
        "Defina la función `do_action` que ejecuta la acción tomada por el agente dentro de la cuadrícula. Esta función recibe como parámetro la acción a ejecutar y retorna el valor de la casilla de llegada de la acción y el estado de llegada de la acción (como una tupla). Note que los movimientos fuera del tablero o las casillas prohibidas no deberían tener ningún efecto en la posición del agente (el agente se debe mantener en la misma posición de partida).\n",
        "\n",
        "En esta versión de gridworld vamos a trabajar con acciones determinísticas, es decir el movimiento deseado del agente (`up`,`right`,`down`,`left`) siempre resultara en el estado esperado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1eb73f2b6fe47f3dd5e95d11c93f5863",
          "grade": false,
          "grade_id": "cell-cef0ee02db9824ce",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fbf0a92c"
      },
      "source": [
        "#### 3. Estado actual\n",
        "\n",
        "Defina la función `get_current_state` que retorna el estado actual del agente (la casilla donde se encuentra el agente). Esta función no recibe ningún parámetro y retorna el estado actual como una tupla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a87b8280f7eaf836d1684523f69c4048",
          "grade": false,
          "grade_id": "cell-a2363364694eb96e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "817babdf"
      },
      "source": [
        "#### 4. Obtener las acciones\n",
        "\n",
        "Defina la función `get_possible_actions` que recibe el estado actual del agente por parámetro y retorna una lista de las acciones válidas para el estado dado.\n",
        "\n",
        "Tenga en cuenta que en esta versión de Gridworld, todas las acciones (i.e., los movimientos en las cuatro direcciones) son posibles para el agente en cada una de las casillas regulares de la cuadrícula. Las casillas de salida tienen única acción posible `'exit'` y las casillas prohibidas no tienen ningúna acción asociada (una lista vacía de acciones)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a939f732e5e93ebcde4c50f067062c07",
          "grade": false,
          "grade_id": "cell-d76f87aa491607d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ffa06d65"
      },
      "source": [
        "\n",
        "#### 5. Reinicializar el ambiente\n",
        "\n",
        "Defina la función `reset` que no recibe parámetros ni retorna ningún valor. El efecto de esta función es restablecer el ambiente a su estado inicial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0a85ca59c65b35130dd2eb2a1e8dff78",
          "grade": false,
          "grade_id": "cell-5761e4534eaa648f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0a9d4f38"
      },
      "source": [
        "\n",
        "#### 6. Estados terminales\n",
        "\n",
        "Defina la función `is_terminal` que determina si el agente está en un estado final o no. En nuestro caso los estados finales o los estados de salida estarán determinados por las casillas con recompensa 1 o -1.\n",
        "Esta función no recibe parámetros y retorna un booleano determinando si el agente está en un estado final o no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cb94b110cc88e9c8b69cad807ccfc213",
          "grade": false,
          "grade_id": "cell-7140c70618ce81ec",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2ccb3db9"
      },
      "source": [
        "## Preguntas de reflexión\n",
        "\n",
        "Considere las siguientes situaciones y piense cual debería ser el resultado del MDP.\n",
        "\n",
        "1. Plantee el problema de MDP para cada una de las casillas. Especifique el estado de inicio, las transiciones y su probabilidad. Para cada acción suponga una probabilidad de éxito de 0.25 (el 0.75 restante se resuelve uniformemente entre las acciones restantes).\n",
        "¿Cómo serían las recompensas esperadas para cada estado?\n",
        "\n",
        "2. Bajo la definción del problema anterior, suponga que ahora cada acción tiene una probabilidad de éxito de 60%, con probabilidad de 30% que se ejecutará la sigiente acción (en dirección de las manesillas del reloj) y con probabilidad de 10% que no se ejecute ninguna acción (el agente se queda quieto). Bajo estas condiciones, ¿Cómo serían las recompensas esperadas para cada estado?\n"
      ]
    }
  ]
}